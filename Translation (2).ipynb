{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lGIJLpgpdG7",
        "colab_type": "code",
        "outputId": "ab9a8371-6ca2-4372-d2de-4cce1a355477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "!pip install transformers==2.5.0\n",
        "!pip install SpaCy tokenizer \n",
        "!pip install ftfy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.5.0 in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (1.13.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (0.1.90)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.5.0 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.0) (1.18.4)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.0) (1.16.10)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.0) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.0) (0.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.0) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.5.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.5.0) (0.15.2)\n",
            "Requirement already satisfied: SpaCy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.6/dist-packages (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from SpaCy) (46.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.18.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->SpaCy) (1.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->SpaCy) (3.1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42wfqGTph-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import AdamW, XLMTokenizer, XLMModel, GPT2Tokenizer, GPT2LMHeadModel, XLMWithLMHeadModel\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import re\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuojeC6PbA2",
        "colab_type": "code",
        "outputId": "56ef1f38-d90d-494e-86ee-c33d08b61510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQB_aIJPtbnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"/content/drive/My Drive/rus.txt\", \"r\")\n",
        "english = []\n",
        "russian = []\n",
        "for line in f:\n",
        "    words = line.split('\\t')\n",
        "    russian.append(words[1])\n",
        "    english.append(words[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy22rC4ZTgnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(russian, columns = ['russian'])\n",
        "data['english'] = english"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCkPYj3CtSvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = re.compile('[A-Za-zА-Яа-яЁёЙй?-]|\\s')\n",
        "data['russian'] = [''.join(re.findall(pattern, x)) for x in data['russian']]\n",
        "data['english'] = [''.join(re.findall(pattern, x)) for x in data['english']]\n",
        "data['russian'] = data['russian'] + [' <to_eng>']*len(data)\n",
        "data['lang'] = data['russian'] + ' '+ data['english']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VMmlXoNrKzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[:50000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJpI4FodXoS",
        "colab_type": "code",
        "outputId": "3d4a4dbe-6151-44e4-9fda-8efd768359ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>russian</th>\n",
              "      <th>english</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Марш &lt;to_eng&gt;</td>\n",
              "      <td>Go</td>\n",
              "      <td>Марш &lt;to_eng&gt; Go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Иди &lt;to_eng&gt;</td>\n",
              "      <td>Go</td>\n",
              "      <td>Иди &lt;to_eng&gt; Go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Идите &lt;to_eng&gt;</td>\n",
              "      <td>Go</td>\n",
              "      <td>Идите &lt;to_eng&gt; Go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Здравствуйте &lt;to_eng&gt;</td>\n",
              "      <td>Hi</td>\n",
              "      <td>Здравствуйте &lt;to_eng&gt; Hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Привет &lt;to_eng&gt;</td>\n",
              "      <td>Hi</td>\n",
              "      <td>Привет &lt;to_eng&gt; Hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>У меня есть работа которую нужно сделать &lt;to_eng&gt;</td>\n",
              "      <td>I have a job to do</td>\n",
              "      <td>У меня есть работа которую нужно сделать &lt;to_e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Мне ещё нужно сделать работу &lt;to_eng&gt;</td>\n",
              "      <td>I have a job to do</td>\n",
              "      <td>Мне ещё нужно сделать работу &lt;to_eng&gt; I have a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>Мне ещё нужно делать работу &lt;to_eng&gt;</td>\n",
              "      <td>I have a job to do</td>\n",
              "      <td>Мне ещё нужно делать работу &lt;to_eng&gt; I have a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>У меня тут список &lt;to_eng&gt;</td>\n",
              "      <td>I have a list here</td>\n",
              "      <td>У меня тут список &lt;to_eng&gt; I have a list here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>У меня много дел &lt;to_eng&gt;</td>\n",
              "      <td>I have a lot to do</td>\n",
              "      <td>У меня много дел &lt;to_eng&gt; I have a lot to do</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 russian  ...                                               lang\n",
              "0                                          Марш <to_eng>  ...                                   Марш <to_eng> Go\n",
              "1                                           Иди <to_eng>  ...                                    Иди <to_eng> Go\n",
              "2                                         Идите <to_eng>  ...                                  Идите <to_eng> Go\n",
              "3                                  Здравствуйте <to_eng>  ...                           Здравствуйте <to_eng> Hi\n",
              "4                                        Привет <to_eng>  ...                                 Привет <to_eng> Hi\n",
              "...                                                  ...  ...                                                ...\n",
              "49995  У меня есть работа которую нужно сделать <to_eng>  ...  У меня есть работа которую нужно сделать <to_e...\n",
              "49996              Мне ещё нужно сделать работу <to_eng>  ...  Мне ещё нужно сделать работу <to_eng> I have a...\n",
              "49997               Мне ещё нужно делать работу <to_eng>  ...  Мне ещё нужно делать работу <to_eng> I have a ...\n",
              "49998                         У меня тут список <to_eng>  ...      У меня тут список <to_eng> I have a list here\n",
              "49999                          У меня много дел <to_eng>  ...       У меня много дел <to_eng> I have a lot to do\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKhos0OCted7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CzKW8SZz7aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, dataset, suftrain=True):\n",
        "        self.df = dataset\n",
        "        self.suftrain = suftrain\n",
        "        X_train, X_test = train_test_split(self.df, test_size=0.2, random_state=42)\n",
        "        if suftrain == True:\n",
        "          self.df = X_train[['russian','english']].reset_index(drop=True)\n",
        "        else:\n",
        "          self.df = X_test[['russian','english']].reset_index(drop=True)\n",
        "        \n",
        "        self.tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "        self.tokenizer.add_tokens(['<to_eng>'])\n",
        "        # self.tokenizer_eng = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "    \n",
        "          sentence_lang = self.df.loc[index, 'english']\n",
        "          sentence_rus = self.df.loc[index, 'russian']\n",
        "          tokens_ids_lang = self.tokenizer.encode(sentence_lang)\n",
        "          tokens_ids_rus = self.tokenizer.encode(sentence_rus)\n",
        "          tokens_ids_tensor_lang = torch.tensor(tokens_ids_lang)\n",
        "          tokens_ids_tensor_rus = torch.tensor(tokens_ids_rus)\n",
        "\n",
        "          return tokens_ids_tensor_rus, tokens_ids_tensor_lang[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhAy701OGBEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TranslateDataset(data, True)\n",
        "test_dataset = TranslateDataset(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UBqQgVwbKx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C8JUT8HeReE",
        "colab_type": "code",
        "outputId": "2297cbe9-ef89-4eaa-fac8-73c800d2f0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_dataset[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    1,  2248,  1572, 12794, 26079,   457,   998, 95000,     1]),\n",
              " tensor([ 2323, 42118, 53124,     1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KCk5hBZazw6",
        "colab_type": "code",
        "outputId": "f82edff2-287f-4bd6-86ee-991f075b827d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(range(15))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '</s>',\n",
              " '<pad>',\n",
              " '<unk>',\n",
              " '<special0>',\n",
              " '<special1>',\n",
              " '<special2>',\n",
              " '<special3>',\n",
              " '<special4>',\n",
              " '<special5>',\n",
              " '<special6>',\n",
              " '<special7>',\n",
              " '<special8>',\n",
              " '<special9>',\n",
              " ',</w>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEcMkVDYli8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    x = x[:-1]\n",
        "    if len(x) <max_len:\n",
        "        # if targ == False:\n",
        "        padded = list(x.numpy()) + [2]*(max_len - len(x))\n",
        "        # else:\n",
        "        #   padded = list(x.numpy()) + [50256]*(max_len - len(x))\n",
        "    else:\n",
        "       padded = list(x.numpy())[:(max_len)]\n",
        "    return padded    \n",
        "\n",
        "\n",
        "class Collator(object):\n",
        "    def __init__(self, percentile=100):\n",
        "        self.percentile = percentile\n",
        "        \n",
        "    def __call__(self, batch):\n",
        "        \n",
        "        inp, targ = zip(*batch)\n",
        "        \n",
        "        lens = [len(x) for x in inp] \n",
        "        max_len = int(np.percentile(lens, self.percentile))\n",
        "        \n",
        "        lens_targ = [len(x) for x in targ]\n",
        "        max_len_targ = int(np.percentile(lens_targ, self.percentile))\n",
        "\n",
        "        inp = torch.from_numpy(np.array([pad_sequences(sentence, max_len) for sentence in inp]))\n",
        "        targ = torch.from_numpy(np.array([pad_sequences(sentence, max_len) for sentence in targ]))\n",
        "        \n",
        "        \n",
        "        return inp, targ\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsXf7OEH7RUS",
        "colab_type": "code",
        "outputId": "57076558-380c-441f-8242-3d5ddbbec3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s34tiMGmBmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#settings\n",
        "batch_size = 64\n",
        "#epoch_dec = 10\n",
        "epochs_dec = 3\n",
        "# learning_rate_dec = 0.0008\n",
        "learning_rate_dec = 0.0005\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B23d8QjnioL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collate = Collator(percentile=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg7FdoT5qL9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=collate)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV54mzVxpucI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3da7864-f6ac-4360-947d-e7fc592472f2"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLs4k8GHqXNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTranslate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelTranslate, self).__init__()\n",
        "        \n",
        "        self.enc = XLMModel.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "        # self.dec = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "        self.dec = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "        self.fc = nn.Linear(1024, 768)\n",
        "        # self.fc1 = nn.Linear(1024, 95001)\n",
        "\n",
        "    def forward(self,seq, labels, suf= 'train'):\n",
        "\n",
        "          self.enc.requires_grad_=False\n",
        "          outputs = self.enc(seq)[0]\n",
        "          outputs = self.fc(outputs)\n",
        "          self.dec.resize_token_embeddings(95001)\n",
        "          self.dec.transformer.wte.parametres = outputs\n",
        "          # for block in range(7,11):\n",
        "          #   self.dec.transformer.h[block].requires_grad_=True\n",
        "          # self.dec.lm_head.requires_grad_=True\n",
        "          self.dec.requires_grad_=True\n",
        "          self.dec.transformer.wte.parametres.requires_grad_=False\n",
        "          # self.dec.pred_layer.requires_grad_=True\n",
        "          # self.dec.transformer.layer_norm_emb.requires_grad_=True\n",
        "          attention_mask = (seq > 4)*1\n",
        "          # inputs_embeds = outputs\n",
        "          \n",
        "          logits = self.dec(seq, labels = seq, attention_mask=attention_mask)[1]\n",
        "          # logits = self.dec(seq, labels=labels,attention_mask=attention_mask)[1]\n",
        "       \n",
        "          \n",
        "          if suf == 'test':\n",
        "            logits = self.dec(seq, attention_mask=attention_mask)[0]\n",
        "          \n",
        "            # for step in range(1,labels.size(1)):\n",
        "            #   seq_tr = seq[:, :(step+1)]\n",
        "            #   attention_mask = (seq_tr == 1)*1\n",
        "            #   if step == 0:\n",
        "            #     targets = labels[:,:(step+1)]\n",
        "             \n",
        "            #     logits = self.dec(seq_tr, labels = targets, attention_mask=attention_mask)[1]            \n",
        "            #   if step > 0:\n",
        "                \n",
        "            #     targets = torch.cat([torch.argmax(logits, dim=-1), labels[:, step].view(-1,1)], dim = -1)\n",
        "            #     logits = self.dec(seq_tr, labels = targets, attention_mask=attention_mask)[1]\n",
        "         \n",
        "          return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGudoy44BTEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  ModelTranslate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8isiuqwBTWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(pred, real):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    total_loss = 0\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for i in range(len(real[0])):\n",
        "      mask = real[:,i].ge(4).cuda()\n",
        "      loss_ = crit(pred[:,i].cuda(), real[:,i].long())*mask\n",
        "      total_loss  =  total_loss + torch.mean(loss_)\n",
        "    return total_loss/len(real[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqEZeMuU-o4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  for i, (seq_test, label_test) in enumerate(test_loader):\n",
        "    seq_test, label_test = seq_test.to(device), label_test.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      test_output = model(seq_test, label_test, 'test')\n",
        "    \n",
        "    test_loss = loss_function(test_output, label_test)\n",
        "    total_loss = total_loss + test_loss\n",
        "    return total_loss/(i+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKCBxcGIEB6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, test_loader, device, epochs_dec):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  \n",
        "  optimizer = AdamW(model.parameters(), lr=learning_rate_dec)\n",
        "  for epoch in range(epochs_dec):\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i , (seq, labels) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      seq, labels = seq.to(device), labels.to(device)\n",
        "\n",
        "      logits = model(seq, labels)\n",
        "     \n",
        "\n",
        "      loss = loss_function(logits, labels)\n",
        "      loss.backward()\n",
        "      total_loss = total_loss + loss\n",
        "     \n",
        "      nn.utils.clip_grad_norm_(model.parameters(),1)\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      \n",
        "    val_loss = evaluate(model, test_loader, device)\n",
        "    print(f'Epoch {epoch}, Train_loss: {total_loss/(i+1)}, Val_loss: {val_loss}')\n",
        "     \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoQne7SxEaPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#firts 7 epochs\n",
        "# Epoch 0, Train_loss: 2.0162532329559326, Val_loss: 1.8534671068191528\n",
        "# Epoch 1, Train_loss: 1.5938363075256348, Val_loss: 1.6540483236312866\n",
        "# Epoch 2, Train_loss: 1.4494097232818604, Val_loss: 1.5349314212799072\n",
        "# Epoch 3, Train_loss: 1.3332741260528564, Val_loss: 1.439836859703064\n",
        "# Epoch 4, Train_loss: 1.2357085943222046, Val_loss: 1.421500325202942\n",
        "# Epoch 5, Train_loss: 1.1564744710922241, Val_loss: 1.4078181982040405\n",
        "# Epoch 6, Train_loss: 1.0948387384414673, Val_loss: 1.433040976524353\n",
        "\n",
        "# Epoch 0, Train_loss: 0.8229318857192993, Val_loss: 1.0416773557662964\n",
        "# Epoch 1, Train_loss: 0.6625553965568542, Val_loss: 1.025605320930481\n",
        "# Epoch 2, Train_loss: 0.6321516633033752, Val_loss: 1.0261223316192627"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXE3cjDIehI",
        "colab_type": "code",
        "outputId": "42125084-7ebb-44e6-9d8e-83d6928660bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "model = train(model, train_loader, test_loader, device, epochs_dec)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train_loss: 0.7088356614112854, Val_loss: 1.0548229217529297\n",
            "Epoch 1, Train_loss: 0.6433326005935669, Val_loss: 0.9938598275184631\n",
            "Epoch 2, Train_loss: 0.6314703822135925, Val_loss: 1.007136583328247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-EGls0wI6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cccda77b-f40d-443f-cc86-7dc9ec8e2f44"
      },
      "source": [
        "test_dataset[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    1,   673, 41287,   906, 95000,     1]),\n",
              " tensor([ 6723,  1739, 51587,   202,     1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv99hozjveS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "for i, (seq_test, label_test) in enumerate(test_loader):\n",
        "    seq_test, label_test = seq_test.to(device), label_test.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      test_output = model(seq_test, label_test, 'test')\n",
        "    if i>=10:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2CTxDZsyWIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f7d23f2-497e-4c78-91a3-8e401c2f4332"
      },
      "source": [
        "tokenizer_eng = XLMTokenizer.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "tokenizer_eng.add_tokens(['<to_eng>'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW_p_9-Yx4qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5796e4b-521f-4066-b8d1-5083b130bc26"
      },
      "source": [
        "for i in range(64):\n",
        "  print('predict:', tokenizer_eng.decode(torch.argmax(test_output[i], dim=1)), ' true:', tokenizer_eng.decode(label_test[i]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict: take this one <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: take that one <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: tom is still sick <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: tom is still up <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: tom is thai <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: tom gloated <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: did was hear me me <pad><pad>me me am am anyone me <pad>  true: can anyone hear me? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: it is be <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: that was pathetic <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: what did you hide? <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: what did you hide? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was with <pad><pad><pad><pad><pad><pad><pad><pad>i <pad><pad>  true: i agree with tom <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: get me work <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: get to work <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: these are ent mine <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: these arent mine <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was you <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i liked to travel <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: dont forget my <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: dont tell anyone <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was your <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i understand why <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: it was dark dark <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: it was dark <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was love <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: ill get up <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: go to <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: go find tom <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was on <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i arrived first <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: he is it friend <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: hes her friend <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: shes was <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: shes my wife <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: does is ks beer <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: does tom drink tea? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was ely sing <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i seldom see tom <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i like very a lot <pad><pad><pad><pad><pad><pad><pad><pad>lot  true: i liked it a lot <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: <unk>you it <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: <unk>naive <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i like nt a <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i wasnt so lucky <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i like stronger <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i feel much better <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: what did he see? <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: what did he see? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: will you sing <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: will you miss me? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: is is a me <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: is this about me? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: copy this file <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: copy this file <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: we all gunde<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: we kept our word <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was too too <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i want one too <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: the door opened <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: the door squeaked <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: he is singing <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: he started to sing <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: did like thirty? <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: did anyone call me? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was tom <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>the  true: i failed chemistry <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: tom is n<pad><pad><pad><pad><pad>a <pad><pad><pad><pad><pad>  true: tom <unk>smoke <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was you <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: ive seen tom <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: you you get a <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: <unk>paying <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: dont forget too much <pad><pad><pad><pad><pad><pad><pad>dont <pad>dont  true: dont buy that <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: <unk>all it <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: <unk>delicious <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: its it your bag <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: its in your bag <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: did you you to <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: did you lie to me? <pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was a doctor ent <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i was negligent <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: you you it hope me <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: you promised me <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: the you is hot dark <pad><pad><pad><pad><pad><pad>the is the  true: the room is dark <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: keep on <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: keep writing <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: the s face with <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: my face was dirty <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: how do you help? <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: how can you lose? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: do you miss boston <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: do you miss it? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: hes is <pad>man <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: hes rich <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: dont forget him me <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: dont rush me <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: tom is the mi<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: tom <unk>humbly <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: who you is <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: whos been shot? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: well all it <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: we will finish it <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: <unk>you happy <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: you lead the way <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i was very <pad><pad><pad><pad><pad><pad>i i i i <pad>  true: i felt humiliated <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: it is nt <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: its not a loan <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: its is <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: now is the time <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: what did you say? <pad><pad><pad><pad>?? <pad>??  true: what did you mean? <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: come it of <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: come out of there <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: i have a a dog <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: i dont have a dog <pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: <unk>you bookworm <pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: <unk>a nerd <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: hes is still angry <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: he is still angry <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: im was <pad>thy <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: im healthy <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "predict: my glass worked <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>  true: my plan is simple <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gan5tPvGysXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29c293e8-bb45-422d-c48e-2535e329a4c2"
      },
      "source": [
        "tokenizer_eng.decode(label_test[45])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tom isnt old <pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2yuFknm5q2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aff9e84-68e8-45c5-ac06-e0f3355466a7"
      },
      "source": [
        "tokenizer_eng.decode(torch.argmax(test_output[45], dim=1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tom is ont old <pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCRACR-Z5rPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAeyrRHfs7iD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4822e71-e602-4d47-da89-5faff09478d5"
      },
      "source": [
        "tokenizer.encode([','])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 24406, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}