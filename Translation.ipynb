{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lGIJLpgpdG7",
        "colab_type": "code",
        "outputId": "d9a6c942-6ee0-4ceb-8dcf-85078f982d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install SpaCy tokenizer \n",
        "!pip install ftfy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: SpaCy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.6/dist-packages (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from SpaCy) (46.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.18.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from SpaCy) (2.0.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->SpaCy) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->SpaCy) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->SpaCy) (3.1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (5.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42wfqGTph-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import AdamW, XLMTokenizer, XLMModel, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import re\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuojeC6PbA2",
        "colab_type": "code",
        "outputId": "ce9912b8-b0b1-400c-c7a7-90f7fa3aa7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQB_aIJPtbnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"/content/drive/My Drive/rus.txt\", \"r\")\n",
        "english = []\n",
        "russian = []\n",
        "for line in f:\n",
        "    words = line.split('\\t')\n",
        "    russian.append(words[1])\n",
        "    english.append(words[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy22rC4ZTgnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(russian, columns = ['russian'])\n",
        "data['english'] = english"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETLkI_vV5te5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKhos0OCted7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CzKW8SZz7aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, dataset, suftrain=True):\n",
        "        self.df = dataset\n",
        "        X_train, X_test = train_test_split(self.df, test_size=0.2, random_state=42)\n",
        "        if suftrain == True:\n",
        "          self.df = X_train.reset_index(drop=True)\n",
        "        else:\n",
        "          self.df = X_test.reset_index(drop=True)\n",
        "        \n",
        "        self.tokenizer_rus = XLMTokenizer.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "        self.tokenizer_eng = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence_rus = self.df.loc[index, 'russian']\n",
        "        sentence_eng = self.df.loc[index, 'english']\n",
        "        tokens_ids_rus = self.tokenizer_rus.encode(sentence_rus)\n",
        "        tokens_ids_eng = self.tokenizer_eng.encode(sentence_eng)\n",
        "        tokens_ids_tensor_rus = torch.tensor(tokens_ids_rus)\n",
        "        tokens_ids_tensor_eng = torch.tensor(tokens_ids_eng)\n",
        "        \n",
        "        return tokens_ids_tensor_rus, tokens_ids_tensor_eng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhAy701OGBEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TranslateDataset(data, True)\n",
        "test_dataset = TranslateDataset(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEcMkVDYli8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len, targ):\n",
        "    if len(x) <max_len:\n",
        "        if targ == False:\n",
        "          padded = list(x.numpy()) + [2]*(max_len - len(x))\n",
        "        else:\n",
        "          padded = list(x.numpy()) + [50256]*(max_len - len(x))\n",
        "    else:\n",
        "       padded = list(x.numpy())[:(max_len)]\n",
        "    return padded    \n",
        "\n",
        "\n",
        "class Collator(object):\n",
        "    def __init__(self, percentile=100):\n",
        "        self.percentile = percentile\n",
        "        \n",
        "    def __call__(self, batch):\n",
        "\n",
        "        \n",
        "        #inp, targ, inp3, lens, lens_targ\n",
        "        \n",
        "        inp, targ = zip(*batch)\n",
        "        \n",
        "        lens = [len(x) for x in inp] \n",
        "        max_len = int(np.percentile(lens, self.percentile))\n",
        "        \n",
        "        lens_targ = [len(x) for x in targ]\n",
        "        max_len_targ = int(np.percentile(lens_targ, self.percentile))\n",
        "\n",
        "        inp = torch.from_numpy(np.array([pad_sequences(sentence, max_len, False) for sentence in inp]))\n",
        "        targ = torch.from_numpy(np.array([pad_sequences(sentence, max_len, True) for sentence in targ]))\n",
        "        \n",
        "        \n",
        "        return inp, targ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsXf7OEH7RUS",
        "colab_type": "code",
        "outputId": "33650d12-9e1f-4835-b242-8d5b9d93a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s34tiMGmBmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#settings\n",
        "batch_size = 100\n",
        "epochs_dec = 15\n",
        "learning_rate_dec = 0.00001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B23d8QjnioL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collate = Collator(percentile=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg7FdoT5qL9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=collate)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13qWxJ8I3Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLs4k8GHqXNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelTranslate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelTranslate, self).__init__()\n",
        "        \n",
        "        self.enc = XLMModel.from_pretrained(\"xlm-mlm-tlm-xnli15-1024\")\n",
        "        self.dec = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "        self.fc = nn.Linear(1024, 768)\n",
        "        \n",
        "    def forward(self,seq, labels, suf= 'train'):\n",
        "\n",
        "          outputs = self.enc(seq)[0]\n",
        "          outputs = self.fc(outputs)\n",
        "          self.dec.transformer.wte.parametres = outputs\n",
        "          for block in range(7,11):\n",
        "            self.dec.transformer.h[block].requires_grad_=True\n",
        "          self.dec.lm_head.requires_grad_=True\n",
        "          self.dec.resize_token_embeddings(95000)\n",
        "          logits = self.dec(seq, labels = labels)[1]  \n",
        "          if suf == 'test':\n",
        "            for step in range(1,labels.size(1)):\n",
        "              seq_tr = seq[:, :(step+1)]\n",
        "              if step == 1:\n",
        "                targets = labels[:,:(step+1)]\n",
        "                logits = self.dec(seq_tr, labels = targets)[1]            \n",
        "              if step > 1:\n",
        "                targets = torch.cat([torch.argmax(logits, dim=-1), labels[:, step].view(-1,1)], dim = -1)\n",
        "                logits = self.dec(seq_tr, labels = targets)[1]\n",
        "          return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGudoy44BTEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  ModelTranslate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVfCX30yJnEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEQ-179Nd7hv",
        "colab_type": "code",
        "outputId": "2379525e-25e9-451c-d650-83b91097a10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.resize_token_embeddings()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8isiuqwBTWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(pred, real):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    total_loss = 0\n",
        "  \n",
        "    for i in range(len(real[0])):\n",
        "        \n",
        "      mask = real[:,i].ge(1).cuda()\n",
        "      crit = nn.CrossEntropyLoss()\n",
        "      loss_ = crit(pred[:,i].cuda(), real[:,i].long()) * mask \n",
        "      total_loss  =  total_loss + torch.mean(loss_)\n",
        "    return total_loss/len(real[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqEZeMuU-o4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  for i, (seq_test, label_test) in enumerate(test_loader):\n",
        "    seq_test, label_test = seq_test.to(device), label_test.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      test_output = model(seq_test, label_test, 'test')\n",
        "    \n",
        "    test_loss = loss_function(test_output, label_test)\n",
        "    total_loss = total_loss + test_loss\n",
        "    return total_loss/(i+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKCBxcGIEB6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, test_loader, device, epochs_dec):\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "  \n",
        "  optimizer = AdamW(model.parameters(), lr=learning_rate_dec)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "  for epoch in range(epochs_dec):\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i , (seq, labels) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      seq, labels = seq.to(device), labels.to(device)\n",
        "\n",
        "      logits = model(seq, labels)\n",
        "\n",
        "      loss = loss_function(logits, labels)\n",
        "      loss.backward()\n",
        "      total_loss = total_loss + loss\n",
        "     \n",
        "      nn.utils.clip_grad_norm_(model.parameters(),0.5)\n",
        "\n",
        "      optimizer.step()\n",
        "      \n",
        "    val_loss = evaluate(model, test_loader, device)\n",
        "    print(f'Epoch {epoch}, Train_loss: {total_loss/(i+1)}, Val_loss: {val_loss}')\n",
        "     \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nXE3cjDIehI",
        "colab_type": "code",
        "outputId": "cdbf457b-40e1-4c73-e3aa-a94bdd16334c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "model = train(model, train_loader, test_loader, device, epochs_dec)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Train_loss: 10.439287185668945, Val_loss: 1.6872849464416504\n",
            "Epoch 1, Train_loss: 1.6729850769042969, Val_loss: 1.4561740159988403\n",
            "Epoch 2, Train_loss: 1.5588891506195068, Val_loss: 1.3970799446105957\n",
            "Epoch 3, Train_loss: 1.4921631813049316, Val_loss: 1.3572216033935547\n",
            "Epoch 4, Train_loss: 1.437381625175476, Val_loss: 1.3161941766738892\n",
            "Epoch 5, Train_loss: 1.4011157751083374, Val_loss: 1.2981739044189453\n",
            "Epoch 6, Train_loss: 1.3514660596847534, Val_loss: 1.2747669219970703\n",
            "Epoch 7, Train_loss: 1.312738060951233, Val_loss: 1.2599109411239624\n",
            "Epoch 8, Train_loss: 1.2797749042510986, Val_loss: 1.242605447769165\n",
            "Epoch 9, Train_loss: 1.2446924448013306, Val_loss: 1.2330267429351807\n",
            "Epoch 10, Train_loss: 1.20681631565094, Val_loss: 1.2241095304489136\n",
            "Epoch 11, Train_loss: 1.177462100982666, Val_loss: 1.2641935348510742\n",
            "Epoch 12, Train_loss: 1.1502277851104736, Val_loss: 1.225440263748169\n",
            "Epoch 13, Train_loss: 1.1105057001113892, Val_loss: 1.2147396802902222\n",
            "Epoch 14, Train_loss: 1.0859723091125488, Val_loss: 1.2193381786346436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-EGls0wI6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "08a84176-c401-4bf1-b321-042e622e7d64"
      },
      "source": [
        "test_dataset[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    1,   435, 37372,  4300,    15,     1]),\n",
              " tensor([  40, 1101,  262, 4870,   13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv99hozjveS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (seq_test, label_test) in enumerate(test_loader):\n",
        "    seq_test, label_test = seq_test.to(device), label_test.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      test_output = model(seq_test, label_test, 'test')\n",
        "    if i>=1:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2CTxDZsyWIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_eng = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW_p_9-Yx4qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ec696ed-e280-4bd7-d8d3-90655d3cf979"
      },
      "source": [
        "tokenizer_eng.decode(torch.argmax(test_output[18], dim=1))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I crying.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gan5tPvGysXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a598394b-9279-4b65-87f4-43068e5220cd"
      },
      "source": [
        "tokenizer_eng.decode(label_test[18])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stop yelling.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}